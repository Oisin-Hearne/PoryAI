{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import showdown\n",
    "import agent\n",
    "import asyncio\n",
    "import torch\n",
    "import json\n",
    "from datetime import datetime\n",
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "async def agent_battle(agent, showdown):\n",
    "    await showdown.restart()\n",
    "    done = False\n",
    "    totalReward = 0\n",
    "    battleProgress = []\n",
    "    \n",
    "    while not done:\n",
    "        state = showdown.getState()\n",
    "        validActions = showdown.getValidActions()\n",
    "        \n",
    "        action = agent.act(state, validActions)\n",
    "        nextState, reward, done, winner = await showdown.executeAction(action)\n",
    "        battleProgress.append((state, action, reward, nextState, done))\n",
    "    \n",
    "    battleReward = -5 if not winner else 5\n",
    "    for i, (state, action, reward, nextState, done) in enumerate(battleProgress):\n",
    "        adjustedReward = reward + (battleReward / (len(battleProgress)))\n",
    "        totalReward += adjustedReward\n",
    "        agent.remember(state, action, adjustedReward, nextState, done)\n",
    "    \n",
    "    print(\"Finishing battle...\")\n",
    "    return winner, totalReward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makePlot(x, y, battle, timestamp):\n",
    "        plt.plot(x, y)\n",
    "        plt.xlabel('Battles')\n",
    "        plt.ylabel('Rewards')\n",
    "        plt.title('Learning Curve')\n",
    "        plt.savefig(f\"data/logs/plots/plot-{battle}-{timestamp}.png\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def training_loop(agent1, agent2, showdown1, showdown2, numBattles=5000):\n",
    "    agent1Wins = 0\n",
    "    rewards1 = 0\n",
    "    plotX = []\n",
    "    plotY = []\n",
    "    \n",
    "    agent2.model.load_state_dict(agent1.model.state_dict())\n",
    "    \n",
    "    for battle in range(numBattles):\n",
    "        \n",
    "        # Concurrently execute both agents and get the results from agent_battle\n",
    "        results = await asyncio.gather(agent_battle(agent1, showdown1), agent_battle(agent2, showdown2))\n",
    "        winner = results[0][0]\n",
    "        \n",
    "        if winner:\n",
    "            agent1Wins += 1\n",
    "            rewards1 += results[0][1]\n",
    "            plotY.append(results[0][1])\n",
    "        else:\n",
    "            rewards1 += results[0][1]\n",
    "            plotY.append(results[0][1])\n",
    "            \n",
    "        agent1.replay()\n",
    "        \n",
    "        plotX.append(battle)\n",
    "        \n",
    "        agent1.replay()        \n",
    "        \n",
    "        # Every 10 battles, output the current state and clear the old output.\n",
    "        # Notebooks are so laggy.\n",
    "        if battle % 10 == 0 and battle > 0:\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            timestamp = datetime.now().strftime(\"%Y_%m%d-%p%I_%M_%S\")\n",
    "            # Save output to file\n",
    "            with open(f\"data/logs/outputs/output-{battle}-{timestamp}.txt\", \"w\") as file:\n",
    "                file.write(f\"Current Stats: \\n Wins This Cycle: {agent1Wins} \\n Battles: {battle} \\n Epsilon: {agent.epsilon}\")\n",
    "             \n",
    "            print(f\"Cleared Output! Current Stats: \\n Wins This Cycle: {agentWins} \\n  Battles: {battle} \\n Epsilon: {agent.epsilon}\")\n",
    "        \n",
    "        # Every 50 battles, save the model and memory.\n",
    "        if battle % 50 == 0 and battle > 0:\n",
    "            \n",
    "            # Reset epsilon according to win ratio\n",
    "            winRatio = agent1Wins / battle\n",
    "            \n",
    "            if winRatio in range(0.40, 0.60):\n",
    "                \n",
    "                # Reset Epsilon\n",
    "                agent1.epsilon = max(agent.epsilon, 0.3)\n",
    "            \n",
    "            # Save model and memory\n",
    "            agent1.saveModel(f\"data/models/model_{battle}.pt\")\n",
    "            agent1.saveMemory(f\"data/memory/memory_{battle}.json\")\n",
    "            \n",
    "            # Save plot\n",
    "            makePlot(plotX, plotY, battle, timestamp)\n",
    "            \n",
    "            # Set agent 2's weights to agent 1's.\n",
    "            agent2.model.load_state_dict(agent1.model.state_dict())\n",
    "\n",
    "            f = open(f\"data/stats/{battle}.json\", \"w\")\n",
    "            f.write(json.dumps({\"wins\": agent1Wins, \"rewards\": rewards1}))\n",
    "            f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "stateSize = 671\n",
    "\n",
    "possibleActions = json.load(open(\"data/possible_actions.json\", \"r\"))\n",
    "actionSize = len(possibleActions)\n",
    "\n",
    "agent1 = agent.Agent(stateSize, actionSize, device, possibleActions)\n",
    "agent2 = agent.Agent(stateSize, actionSize, device, possibleActions)\n",
    "#newAgent.loadModel(\"data/models/model_450.pt\")\n",
    "#newAgent.loadMemory(\"data/memory/memory_450.json\")\n",
    "\n",
    "sd1 = showdown.Showdown(\"https://play.pokemonshowdown.com/action.php\", \"PoryAI-1\", \"password\", \"ws://localhost:8000/showdown/websocket\", \"gen9randombattle\", True)\n",
    "sd2 = showdown.Showdown(\"https://play.pokemonshowdown.com/action.php\", \"PoryAI-2\", \"password\", \"ws://localhost:8000/showdown/websocket\", \"gen9randombattle\", False)\n",
    "await sd1.connectNoSecurity()\n",
    "await sd2.connectNoSecurity()\n",
    "await training_loop(agent1, agent2, sd1, sd2, 10000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
